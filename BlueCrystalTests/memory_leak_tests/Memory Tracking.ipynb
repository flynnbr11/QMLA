{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function # so print doesn't show brackets\n",
    "import numpy as np\n",
    "import itertools as itr\n",
    "\n",
    "import os as os\n",
    "import sys as sys \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time as time\n",
    "import random\n",
    "\n",
    "sys.path.append(os.path.join(\"..\", \"..\",\"Libraries\",\"QML_lib\"))\n",
    "import Evo as evo\n",
    "import DataBase \n",
    "import QMD\n",
    "import QML\n",
    "import ModelGeneration\n",
    "import BayesF\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# plt.switch_backend('agg')\n",
    "\n",
    "global paulis_list\n",
    "paulis_list = {'i' : np.eye(2), 'x' : evo.sigmax(), 'y' : evo.sigmay(), 'z' : evo.sigmaz()}\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message='Negative weights occured', category=RuntimeWarning)\n",
    "num_tests = 1\n",
    "\n",
    "def get_directory_name_by_time(just_date=False):\n",
    "    import datetime\n",
    "    # Directory name based on date and time it was generated \n",
    "    # from https://www.saltycrane.com/blog/2008/06/how-to-get-current-date-and-time-in/\n",
    "    now =  datetime.date.today()\n",
    "    year = now.strftime(\"%y\")\n",
    "    month = now.strftime(\"%b\")\n",
    "    day = now.strftime(\"%d\")\n",
    "    hour = datetime.datetime.now().hour\n",
    "    minute = datetime.datetime.now().minute\n",
    "    date = str (str(day)+'_'+str(month)+'_'+str(year) )\n",
    "    time = str(str(hour)+'_'+str(minute))\n",
    "    name = str(date+'/'+time+'/')\n",
    "    if just_date is False:\n",
    "        return name\n",
    "    else: \n",
    "        return str(date+'/')\n",
    "    \n",
    "# Set parameters for tests\n",
    "\n",
    "do_iqle = True\n",
    "do_qle = False\n",
    "\n",
    "do_summary_plots = True\n",
    "do_intermediate_plots = True\n",
    "save_figs = True\n",
    "save_intermediate_data = True\n",
    "save_summary_data = True\n",
    "\n",
    "plot_time = get_directory_name_by_time(just_date=False) # rather than calling at separate times and causing confusion\n",
    "\n",
    "\n",
    "if num_tests == 1:\n",
    "    intermediate_plots = False\n",
    "else:\n",
    "    intermediate_plots = do_intermediate_plots\n",
    "\n",
    "\n",
    "vary_resample_thresh = False\n",
    "vary_resample_a = False\n",
    "vary_pgh_factor = False\n",
    "\n",
    "variable_parameter = 'vary'\n",
    "\n",
    "best_resample_threshold = 0.65\n",
    "best_resample_a = 0.9\n",
    "best_pgh = 1.4\n",
    "\n",
    "a_options = [best_resample_a]\n",
    "resample_threshold_options = [best_resample_threshold]\n",
    "pgh_options = [best_pgh]\n",
    "\n",
    "if vary_resample_thresh : \n",
    "    variable_parameter += '_thresh'\n",
    "    resample_threshold_options = np.arange(0.35, 0.75, 0.1)\n",
    "\n",
    "if vary_resample_a: \n",
    "    variable_parameter += '_a'\n",
    "    a_options = np.arange(0.85, 0.99, 0.05)\n",
    "\n",
    "if vary_pgh_factor:\n",
    "    variable_parameter += '_pgh'\n",
    "    pgh_options = np.arange(0.6, 1.5, 0.4)\n",
    "\n",
    "    \n",
    "    \n",
    "#### Class Definition ####\n",
    "\n",
    "class NewQMDClass():\n",
    "    #TODO: rename as ModelsDevelopmentClass when finished\n",
    "    def __init__(self,\n",
    "                 initial_op_list,\n",
    "                 true_operator='x',\n",
    "                 true_param_list = None,\n",
    "                 num_particles=1000,\n",
    "                 max_num_models=10, \n",
    "                 max_num_qubits=4, \n",
    "                 gaussian=True,\n",
    "                 resample_threshold = 0.5,\n",
    "                 resampler_a = 0.95,\n",
    "                 pgh_prefactor = 1.0,\n",
    "                 max_num_layers = 10,\n",
    "                 max_num_branches = 20, \n",
    "                 use_exp_custom = True,\n",
    "                 debug_directory = None,\n",
    "                 qle = True # Set to False for IQLE\n",
    "                ):\n",
    "#    def __init__(self, initial_op_list, true_op_list, true_param_list):\n",
    "        self.QLE = qle # Set to False for IQLE\n",
    "        trueOp = DataBase.operator(true_operator)\n",
    "        self.TrueOpName = true_operator\n",
    "        self.TrueOpDim = trueOp.num_qubits\n",
    "        self.InitialOpList = initial_op_list\n",
    "        self.TrueOpList = trueOp.constituents_operators\n",
    "        if true_param_list is not None: \n",
    "            self.TrueParamsList = true_param_list\n",
    "        else:\n",
    "            print(\"No parameters passed, randomising\")\n",
    "            self.TrueParamsList = [random.random() for i in self.TrueOpList] # TODO: actual true params?\n",
    "        # todo set true parmams properly\n",
    "        #self.TrueParamsList = [0.75 for i in self.TrueOpList] # TODO: actual true params?\n",
    "        #self.TrueHam = evo.getH(self.TrueParamsList, self.TrueOpList)\n",
    "        self.TrueHam = np.tensordot(self.TrueParamsList, self.TrueOpList, axes=1)\n",
    "        self.MaxModNum = max_num_models #TODO: necessary?\n",
    "        self.gaussian = gaussian\n",
    "        self.NumModels = len(initial_op_list)\n",
    "        self.NumParticles = num_particles\n",
    "        self.MaxQubitNumber = max_num_qubits\n",
    "        self.ResampleThreshold = resample_threshold\n",
    "        self.ResamplerA = resampler_a\n",
    "        self.PGHPrefactor = pgh_prefactor\n",
    "        self.NumProbes = 40\n",
    "        self.ProbeDict = separable_probe_dict(max_num_qubits=self.MaxQubitNumber, num_probes=self.NumProbes)\n",
    "        self.HighestQubitNumber = int(0)\n",
    "        self.MaxBranchID = max_num_branches\n",
    "        self.HighestBranchID = 0\n",
    "        self.HighestModelID = len(initial_op_list)\n",
    "        self.MaxLayerNumber = max_num_layers\n",
    "        self.BranchChampions = {}\n",
    "        self.LayerChampions = {}\n",
    "        self.BayesFactorsByBranch ={}\n",
    "        self.BranchRankings = {}\n",
    "        self.BranchBayesComputed = {}\n",
    "        self.InterBranchChampions = {}\n",
    "        self.GlobalEpoch = 0 \n",
    "        self.UseExpCustom = use_exp_custom\n",
    "        self.DebugDirectory = debug_directory\n",
    "        \n",
    "        self.BranchBayesComputed[0] = False\n",
    "#        for i in range(self.MaxBranchID+1):\n",
    "#            self.BranchChampions[i] = 0\n",
    "#        for i in range(self.MaxLayerNumber+1):\n",
    "#            self.LayerChampions[i] = 0\n",
    "        \n",
    "        if self.QLE:\n",
    "            print(\"Running QLE for true operator \", true_operator, \" with parameters : \", self.TrueParamsList)\n",
    "        else: \n",
    "            print(\"Running IQLE for true operator \", true_operator, \" with parameters : \", self.TrueParamsList)\n",
    "        # Initialise database and lists.\n",
    "        self.initiateDB()\n",
    "        \n",
    "    def initiateDB(self):\n",
    "        \n",
    "        ## TODO: Models should be initialised with appropriate TrueOp dimension -- see getListTrueOpByDimension function\n",
    "        self.db, self.legacy_db, self.model_lists = \\\n",
    "            DataBase.launch_db(\n",
    "                true_op_name = self.TrueOpName,\n",
    "                gen_list = self.InitialOpList,\n",
    "                qle = self.QLE,\n",
    "                true_ops = self.TrueOpList,\n",
    "                true_params = self.TrueParamsList,\n",
    "                num_particles = self.NumParticles,\n",
    "                redimensionalise = False,\n",
    "                resample_threshold = self.ResampleThreshold,\n",
    "                resampler_a = self.ResamplerA,\n",
    "                pgh_prefactor = self.PGHPrefactor,\n",
    "                num_probes = self.NumProbes,\n",
    "                probe_dict = self.ProbeDict,\n",
    "                use_exp_custom = self.UseExpCustom,\n",
    "                debug_directory = self.DebugDirectory\n",
    "            )\n",
    "    def addModel(self, model, branchID=0):\n",
    "        #self.NumModels += 1\n",
    "        tryAddModel = DataBase.add_model(\n",
    "            model_name = model,\n",
    "            running_database = self.db,\n",
    "            num_particles = self.NumParticles, \n",
    "            true_op_name = self.TrueOpName,\n",
    "            model_lists = self.model_lists,\n",
    "            true_ops = self.TrueOpList,\n",
    "            true_params = self.TrueParamsList,\n",
    "            branchID = branchID,\n",
    "            resample_threshold = self.ResampleThreshold,\n",
    "            resampler_a = self.ResamplerA,\n",
    "            pgh_prefactor = self.PGHPrefactor,\n",
    "            num_probes = self.NumProbes,\n",
    "            probe_dict = self.ProbeDict,\n",
    "            use_exp_custom = self.UseExpCustom,\n",
    "            debug_directory = self.DebugDirectory,\n",
    "            modelID = self.NumModels,\n",
    "            redimensionalise = False,\n",
    "            qle = self.QLE\n",
    "        )\n",
    "        if tryAddModel == True: ## keep track of how many models/branches in play\n",
    "            self.HighestModelID += 1 \n",
    "            self.NumModels += 1\n",
    "            if DataBase.get_num_qubits(model) > self.HighestQubitNumber:\n",
    "                self.HighestQubitNumber = DataBase.get_num_qubits(model)\n",
    "        #else: \n",
    "        #    self.NumModels-=int(1)\n",
    "\n",
    "    def newBranch(self, model_list):\n",
    "        self.HighestBranchID += 1\n",
    "        branchID = self.HighestBranchID\n",
    "        self.BranchBayesComputed[branchID] = False\n",
    "        for model in model_list:\n",
    "            self.addModel(model, branchID=branchID)\n",
    "    \n",
    "    def printState(self):\n",
    "        print(\"Branch champions: \\n\", self.BranchChampions)\n",
    "        print(\"InterBranch champions: \\n\", self.InterBranchChampions)\n",
    "        print(\"Branch Rankings: \\n\", self.BranchRankings)\n",
    "        #print(\"Layer Champions: \\n\", self.LayerChampions)\n",
    "            \n",
    "            \n",
    "    def getModelInstance(self, name):\n",
    "        try: \n",
    "            instance = DataBase.get_qml_instance(self.db, name)\n",
    "            return instance\n",
    "        except: \n",
    "            if name in list(self.legacy_db['<Name>']):\n",
    "                print(\"Operator in legacy databse - retired. \")\n",
    "            else: \n",
    "                print(\"Model not found.\")\n",
    "    def getOperatorInstance(self, name):\n",
    "        try: \n",
    "            return DataBase.get_operator_instance(self.db, name)\n",
    "        except:\n",
    "            if name in list(self.legacy_db['<Name>']):\n",
    "                print(\"Operator in legacy databse - retired. \")\n",
    "            else: \n",
    "                print(\"Operator not found.\")\n",
    "\n",
    "    def getModelDBIndex(self, name):\n",
    "        return DataBase.get_location(self.db, name)\n",
    "\n",
    "    def getModelInstanceFromID(self, model_id):\n",
    "        return DataBase.model_instance_from_id(self.db, model_id)    \n",
    "    \n",
    "    def killModel(self, name):\n",
    "        if name not in list(self.db['<Name>']):\n",
    "            print(\"Cannot remove \", name, \"; not in \", list(self.db[\"<Name>\"]))\n",
    "        else:\n",
    "            print(\"Killing model\", name)\n",
    "            # Add to legacy_db\n",
    "            DataBase.move_to_legacy(self.db, self.legacy_db, name)\n",
    "            model_instance = self.getModelInstance(name)\n",
    "            operator_instance = self.getOperatorInstance(name)\n",
    "            # Remove from self.db\n",
    "            self.db = DataBase.remove_model(self.db, name)\n",
    "            # del model_instance\n",
    "            # del operator_instance\n",
    "    \n",
    "            #TODO: plot?\n",
    "\n",
    "    def runIQLE(self, model, num_exp=50):\n",
    "        model_exists=False\n",
    "        if model in list(self.db['<Name>']):\n",
    "            model_exists = True\n",
    "        elif model in list(self.legacy_db['<Name>']):\n",
    "            print(\"Model \", model, \" previously considered and retired.\")\n",
    "        \n",
    "        has_model_finished = self.pullField(name=model, field='Completed')\n",
    "        \n",
    "        if model_exists==True and has_model_finished==False : \n",
    "            model_instance = self.getModelInstance(model)\n",
    "            print(\"\\nRunning IQLE for model: \", model)\n",
    "            model_instance.UpdateModel(num_exp, checkloss=False)\n",
    "            self.updateModelRecord(name=model, field='Completed', new_value=True)\n",
    "            #model_instance.BayesOnModelsWithinbranches\n",
    "        else: \n",
    "            print(\"Model \", model ,\"does not exist\")\n",
    "\n",
    "    def runAllActiveModelsIQLE(self, num_exp):\n",
    "        active_models = self.db.loc[self.db['Status']=='Active']['<Name>']\n",
    "\n",
    "        for model in active_models:\n",
    "            self.runIQLE(model=model, num_exp=num_exp)\n",
    "        self.GlobalEpoch += num_exp\n",
    "            \n",
    "        \n",
    "    def updateModelRecord(self, field, name=None, model_id=None, new_value=None, increment=None):\n",
    "        DataBase.update_field(\n",
    "            db=self.db, \n",
    "            name=name,\n",
    "            model_id=model_id,\n",
    "            field=field,\n",
    "            new_value=new_value,\n",
    "            increment=increment\n",
    "        )\n",
    "    def pullField(self, name, field):\n",
    "        return DataBase.pull_field(self.db, name, field)\n",
    "\n",
    "    def statusChangeBranch(self, branchID, new_status='Saturated'):\n",
    "        self.db.loc[ self.db['branchID']==branchID , 'Status'] = new_status\n",
    "\n",
    "    def statusChangeModel(self, model_name, new_status='Saturated'):\n",
    "        self.db.loc[ self.db['<Name>']==model_name , 'Status'] = new_status\n",
    "        \n",
    "    def getListTrueOpByDimension(self):\n",
    "        self.TrueOpListByDim = {}\n",
    "        self.TrueParamByDim = {}\n",
    "        for dim in range(1, 1+self.MaxDimension):\n",
    "            new_op = ModelGeneration.identity_interact(subsystem=self.TrueOpName, num_qubits=dim, return_operator=True)\n",
    "            self.TrueOpListByDim[dim] = new_op.constituents_operators\n",
    "        for i in range(1, self.TrueOpDim+1):\n",
    "            self.TrueParamByDim[i] = self.TrueParamsList\n",
    "        for i in range(self.TrueOpDim+1, self.MaxDimension):\n",
    "            self.TrueParamByDim[i] = [self.TrueParamsList[0]]\n",
    "\n",
    "    def compareModels(self, log_comparison_high=50.0, num_times_to_use = 'all', model_a_id = None, model_b_id =None, model_a = None, model_b = None, name_a=None, name_b=None):\n",
    "        # Either pass in name_a and name_b OR model_a and model_b\n",
    "        if model_a is None and model_b is None:\n",
    "            if model_a_id is not None and model_b_id is not None: \n",
    "                model_a = self.getModelInstanceFromID(model_a_id)\n",
    "                model_b = self.getModelInstanceFromID(model_b_id)\n",
    "            else: # if only names were passed \n",
    "                model_a = self.getModelInstance(name_a)\n",
    "                model_b = self.getModelInstance(name_b)\n",
    "        if model_a ==  model_b:\n",
    "            return \"Same Models\"\n",
    "        else: \n",
    "            log_comparison_low = 1.0/log_comparison_high\n",
    "            if model_a_id is None and model_b is None:\n",
    "                model_a_id = model_a.ModelID\n",
    "                model_b_id = model_b.ModelID\n",
    "\n",
    "            if num_times_to_use == 'all':\n",
    "                times_a = model_a.TrackTime\n",
    "            elif len(model_a.TrackTime) < num_times_to_use:\n",
    "                times_a = model_a.TrackTime\n",
    "            else: \n",
    "                times_a = model_a.TrackTime[num_times_to_use:]\n",
    "\n",
    "            if num_times_to_use=='all':\n",
    "                times_b = model_b.TrackTime\n",
    "            elif len(model_b.TrackTime) < num_times_to_use:\n",
    "                times_b = model_b.TrackTime\n",
    "            else: \n",
    "                times_b = model_b.TrackTime[num_times_to_use:]\n",
    "            gen_a = model_a.GenSimModel\n",
    "            gen_b = model_b.GenSimModel\n",
    "\n",
    "            times = times_a + times_b\n",
    "            exps_a = get_exps(model_a, gen_a, times)\n",
    "            exps_b = get_exps(model_b, gen_b, times)\n",
    "\n",
    "            log_l_a =  get_log_likelihood(model_a, gen_a, exps_a)\n",
    "            log_l_b =  get_log_likelihood(model_b, gen_b, exps_b)\n",
    "\n",
    "            print(\"log likelihoods\")\n",
    "            print(name_a, \" : \", log_l_a)\n",
    "            print(name_b, \" : \", log_l_b)\n",
    "#            bayes_factor = np.expm1(log_l_a - log_l_b) +1 #todo: is this the right exp function?\n",
    "            bayes_factor = np.exp(log_l_a - log_l_b)\n",
    "            model_a.addBayesFactor(compared_with=model_b_id, bayes_factor=bayes_factor)\n",
    "            model_b.addBayesFactor(compared_with=model_a_id, bayes_factor=1.0/bayes_factor)\n",
    "\n",
    "            if bayes_factor >= log_comparison_high: \n",
    "             #   print(\"Point to \", model_a.Name)\n",
    "                return \"a\"\n",
    "            elif bayes_factor < log_comparison_low: \n",
    "             #   print(\"Point to \", model_b.Name)\n",
    "                return \"b\"\n",
    "            #else:\n",
    "            #    print(\"No real winner\")  \n",
    "            # todo: Add bayes_factor with mod_id's to QML class\n",
    "\n",
    "            \n",
    "    def compareModelsWithinBranch(self, branchID):\n",
    "        active_models_in_branch = DataBase.active_model_ids_by_branch_id(self.db, branchID)\n",
    "        \n",
    "        models_points = {}\n",
    "        for model_id in active_models_in_branch:\n",
    "            models_points[model_id] = 0\n",
    "        \n",
    "        for i in range(len(active_models_in_branch)):\n",
    "            mod1 = active_models_in_branch[i]\n",
    "            for j in range(i, len(active_models_in_branch)): \n",
    "                mod2 = active_models_in_branch[j]\n",
    "                res = self.compareModels(model_a_id = mod1, model_b_id=mod2)\n",
    "                if res == \"a\":\n",
    "                    models_points[mod1] += 1\n",
    "                elif res == \"b\":\n",
    "                    models_points[mod2] += 1\n",
    "                    # todo if more than one model has max points\n",
    "                    \n",
    "        max_points = max(models_points.values())\n",
    "        max_points_branches = [key for key, val in models_points.items() if val==max_points]\n",
    "        if len(max_points_branches) > 1: \n",
    "            # todo: recompare. Fnc: compareListOfModels (rather than branch based)\n",
    "            champ_id = self.compareModelList(max_points_branches, bayes_threshold=1, models_points_dict=models_points)\n",
    "        else: \n",
    "            champ_id = max(models_points, key=models_points.get)\n",
    "        champ_name = DataBase.model_name_from_id(self.db, champ_id)\n",
    "        \n",
    "        #todo list of ranked models by branch\n",
    "        \n",
    "        self.BranchChampions[int(branchID)] = champ_id\n",
    "        for model_id in active_models_in_branch:\n",
    "            self.updateModelRecord(model_id=model_id, field='Status', new_value='Deactivated')\n",
    "        self.updateModelRecord(name=DataBase.model_name_from_id(self.db, champ_id), field='Status', new_value='Active')\n",
    "\n",
    "        ranked_model_list = sorted_keys = sorted(models_points, key=models_points.get, reverse=True)\n",
    "\n",
    "        if self.BranchBayesComputed[int(float(branchID))] == False: # only update self.BranchRankings the first time branch is considered\n",
    "            self.BranchRankings[int(float(branchID))] = ranked_model_list\n",
    "            self.BranchBayesComputed[int(float(branchID))] = True\n",
    "            \n",
    "        print(\"Champion of branch \", branchID, \" is \", champ_name)\n",
    "        return models_points, champ_id\n",
    "\n",
    "    \n",
    "    def compareModelList(self, model_list, bayes_threshold = 50, models_points_dict=None):\n",
    "        models_points = {}\n",
    "        for mod in model_list:\n",
    "            models_points[mod] = 0\n",
    "        \n",
    "        for i in range(len(model_list)):\n",
    "            mod1 = model_list[i]\n",
    "            for j in range(i, len(model_list)):\n",
    "                mod2 = model_list[j]\n",
    "                if mod1 != mod2:\n",
    "                    res = self.compareModels(model_a_id=mod1, model_b_id=mod2, log_comparison_high=bayes_threshold)\n",
    "                    if res == \"a\":\n",
    "                        models_points[mod1] += 1\n",
    "                        if models_points_dict is not None: \n",
    "                            models_points_dict[mod1]+=1\n",
    "                    elif res == \"b\":\n",
    "                        models_points[mod2]+=1\n",
    "                        if models_points_dict is not None: \n",
    "                            models_points_dict[mod2]+=1\n",
    "\n",
    "        max_points = max(models_points.values())\n",
    "        max_points_branches = [key for key, val in models_points.items() if val==max_points]\n",
    "        if len(max_points_branches) > 1: \n",
    "            # todo: recompare. Fnc: compareListOfModels (rather than branch based)\n",
    "            print(\"No distinct champion, recomputing bayes factors between : \", max_points_branches)\n",
    "            champ_id = self.compareModelList(max_points_branches, bayes_threshold=1)\n",
    "        else: \n",
    "            champ_id = max(models_points, key=models_points.get)\n",
    "        champ_name = DataBase.model_name_from_id(self.db, champ_id)\n",
    "\n",
    "        \n",
    "        return champ_id\n",
    "    \n",
    "    def interBranchChampion(self, branch_list=[], global_champion=False):\n",
    "        all_branches = self.db['branchID'].unique()\n",
    "        if global_champion == True: \n",
    "            branches = all_branches\n",
    "        else: \n",
    "            branches = branch_list\n",
    "        \n",
    "        num_branches = len(branches)\n",
    "        points_by_branches = [None] * num_branches\n",
    "        champions_of_branches = [None] * num_branches\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branchID = branches[i]\n",
    "            if branchID not in all_branches:\n",
    "                print(\"branch ID : \", branchID)\n",
    "                warnings.warn(\"branch not in database.\")\n",
    "                return False\n",
    "            points_by_branches[i], champions_of_branches[i] = qmd.compareModelsWithinBranch(branchID)\n",
    "\n",
    "        branch_champions_points = {}\n",
    "        for c in champions_of_branches: \n",
    "            branch_champions_points[c] = 0\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            mod1 = champions_of_branches[i]\n",
    "            for j in range(i, num_branches):\n",
    "                mod2 = champions_of_branches[j]\n",
    "                if mod1!=mod2:\n",
    "                    res = self.compareModels(model_a_id=mod1, model_b_id=mod2, log_comparison_high=20.0)\n",
    "                    if res == \"a\":\n",
    "                        branch_champions_points[mod1] += 1\n",
    "                    elif res == \"b\":\n",
    "                        branch_champions_points[mod2] += 1\n",
    "        self.ranked_champions = sorted(branch_champions_points, reverse=True)\n",
    "        \n",
    "        max_points = max(branch_champions_points.values())\n",
    "        max_points_branches = [key for key, val in branch_champions_points.items() if val==max_points]\n",
    "        if len(max_points_branches) > 1: \n",
    "            # todo: recompare. Fnc: compareListOfModels (rather than branch based)\n",
    "            print(\"No distinct champion, recomputing bayes factors between : \", max_points_branches)\n",
    "            champ_id = self.compareModelList(max_points_branches, bayes_threshold=1, models_points_dict=branch_champions_points)\n",
    "        else: \n",
    "            champ_id = max(branch_champions_points, key=branch_champions_points.get)\n",
    "        champ_name = DataBase.model_name_from_id(self.db, champ_id)\n",
    "        \n",
    "        branch_champ_names = [DataBase.model_name_from_id(self.db, mod_id) for mod_id in champions_of_branches]\n",
    "        self.statusChangeModel(champ_name, new_status = 'Active')\n",
    "        \n",
    "        interBranchChampListID = len(self.InterBranchChampions)\n",
    "        self.InterBranchChampions[interBranchChampListID] = [branches, champ_id]\n",
    "        return champ_name, branch_champ_names\n",
    "    \n",
    "    def globalChampionCalculation(self):\n",
    "        branches = self.db['branchID'].unique()\n",
    "        \n",
    "        num_branches = len(branches)\n",
    "        self.points_by_branches = [None] * num_branches\n",
    "        self.champions_of_branches = [None] * num_branches\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            branchID = branches[i]\n",
    "            self.points_by_branches[i], self.champions_of_branches[i] = qmd.compareModelsWithinBranch(branchID)\n",
    "\n",
    "        self.champions_points = {}\n",
    "        for c in self.champions_of_branches: \n",
    "            self.champions_points[c] = 0\n",
    "\n",
    "        for i in range(num_branches):\n",
    "            mod1 = self.champions_of_branches[i]\n",
    "            for j in range(i, num_branches):\n",
    "                mod2 = self.champions_of_branches[j]\n",
    "                if mod1!=mod2:\n",
    "                    res = self.compareModels(model_a_id=mod1, model_b_id=mod2, log_comparison_high=10.0)\n",
    "                    if res == \"a\":\n",
    "                        self.champions_points[mod1] += 1\n",
    "                    elif res == \"b\":\n",
    "                        self.champions_points[mod2]+=1\n",
    "        self.ranked_champions = sorted(self.champions_points, reverse=True)\n",
    "        champ_id = max(self.champions_points, key=self.champions_points.get)\n",
    "        champ_name = DataBase.model_name_from_id(self.db, champ_id)\n",
    "        print(\"Champion of Champions is\",  champ_name)\n",
    "        \n",
    "        \n",
    "    def spawn(self, \n",
    "              branch_list = None, \n",
    "              num_models_to_consider=1, \n",
    "              absolute_champion=False, \n",
    "              all_branches=False\n",
    "             ):\n",
    "\n",
    "        if all_branches or branch_list is None: \n",
    "            global_champion = True\n",
    "            \n",
    "        overall_champ, branch_champions = self.interBranchChampion(branch_list=branch_list, global_champion=global_champion)\n",
    "\n",
    "        if absolute_champion:\n",
    "            new_models = ModelGeneration.new_model_list(model_list=[overall_champ], generator='simple_ising',options=['x', 'y'])\n",
    "        else: \n",
    "            new_models = ModelGeneration.new_model_list(model_list=branch_champions, generator='simple_ising', options=['x', 'y'])\n",
    "        \n",
    "        print(\"New models to add to new branch : \", new_models)\n",
    "        qmd.newBranch(model_list=new_models) \n",
    "        \n",
    "        #todo probailistically append model_list with suboptimal model in any of the branches in branch_list\n",
    "\n",
    "    def runQMD(self, num_exp = 20, max_branches= None, max_num_qubits = None, max_num_models=None):\n",
    "        if max_branches is None:\n",
    "            max_branches = self.MaxBranchID\n",
    "\n",
    "        if max_num_qubits is None:\n",
    "            max_num_qubits = self.MaxQubitNumber\n",
    "            \n",
    "        if max_num_models is None: \n",
    "            max_num_models = self.MaxModNum\n",
    "            \n",
    "        while self.HighestQubitNumber < max_num_qubits: \n",
    "            self.runAllActiveModelsIQLE(num_exp=num_exp)\n",
    "            self.spawn()\n",
    "            if self.HighestBranchID > max_branches or self.NumModels > max_num_models:\n",
    "                break\n",
    "            \n",
    "        self.runAllActiveModelsIQLE(num_exp=num_exp)\n",
    "        final_winner, final_branch_winners = self.interBranchChampion(global_champion=True)\n",
    "        print(\"Final winner = \", final_winner)\n",
    "\n",
    "    def inspectModel(self, name):\n",
    "        print(\"\\nmodel name: \", name)\n",
    "        mod = self.getModelInstance(name)\n",
    "        \n",
    "        print(\"experiments done \", mod.NumExperimentsToDate)\n",
    "        print(\"times: \",  mod.TrackTime)\n",
    "        print(\"final params : \", mod.FinalParams)\n",
    "        print(\"bayes factors: \", mod.BayesFactors)\n",
    "        \n",
    "def get_exps(model, gen, times):\n",
    "\n",
    "    exps = np.empty(len(times), dtype=gen.expparams_dtype)\n",
    "    exps['t'] = times\n",
    "\n",
    "    for i in range(1, len(gen.expparams_dtype)):\n",
    "        col_name = 'w_'+str(i)\n",
    "        exps[col_name] = model.FinalParams[i-1,0] ## TODO: should be model.NewEval[i-1]???\n",
    "    return exps\n",
    "\n",
    "def get_log_likelihood(model, gen, exps):\n",
    "    import copy\n",
    "    updater = copy.deepcopy(model.Updater)\n",
    "    data = gen.simulate_experiment(model.SimParams, exps)[0][0]\n",
    "    updater.batch_update(data, exps, resample_interval=100)\n",
    "\n",
    "    log_likelihood = updater.log_total_likelihood\n",
    "    #if log_likelihood < 10e-16:\n",
    "    #    print(\"log likelihood = \", log_likelihood, \" so replacing with \", 1e-9)\n",
    "    #    log_likelihood = 10e-16\n",
    "    del updater\n",
    "    #print(\"log likelihood = \", log_likelihood)\n",
    "    return log_likelihood        \n",
    "\n",
    "\n",
    "def separable_probe_dict(max_num_qubits, num_probes):\n",
    "    seperable_probes = {}\n",
    "    for i in range(num_probes):\n",
    "        seperable_probes[i,0] = random_probe(1)\n",
    "        for j in range(1, 1+max_num_qubits):\n",
    "            if j==1:\n",
    "                seperable_probes[i,j] = seperable_probes[i,0]\n",
    "            else: \n",
    "                seperable_probes[i,j] = np.tensordot(seperable_probes[i,j-1], random_probe(1), axes=0).flatten(order='c')\n",
    "            if np.linalg.norm(seperable_probes[i,j]) < 0.999999999 or np.linalg.norm(seperable_probes[i,j]) > 1.0000000000001:\n",
    "                print(\"non-unit norm: \", np.linalg.norm(seperable_probes[i,j]))\n",
    "    return seperable_probes\n",
    "\n",
    "def random_probe(num_qubits):\n",
    "    dim = 2**num_qubits\n",
    "    real = np.random.rand(1,dim)\n",
    "    imaginary = np.random.rand(1,dim)\n",
    "    complex_vectors = np.empty([1, dim])\n",
    "    complex_vectors = real +1.j*imaginary\n",
    "    norm_factor = np.linalg.norm(complex_vectors)\n",
    "    probe = complex_vectors/norm_factor\n",
    "    return probe[0][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "\n",
    "### Plotting functions \n",
    "\n",
    "#######################################\n",
    "\n",
    "global iqle_intermediate_medians \n",
    "global iqle_intermediate_means\n",
    "global iqle_intermediate_mins \n",
    "global iqle_intermediate_maxs \n",
    "global iqle_intermediate_std_devs \n",
    "\n",
    "global qle_intermediate_medians \n",
    "global qle_intermediate_means\n",
    "global qle_intermediate_mins \n",
    "global qle_intermediate_maxs \n",
    "global qle_intermediate_std_devs \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def store_data_for_plotting(iqle_qle):\n",
    "    \n",
    "    global iqle_intermediate_medians \n",
    "    global iqle_intermediate_means\n",
    "    global iqle_intermediate_mins \n",
    "    global iqle_intermediate_maxs \n",
    "    global iqle_intermediate_std_devs \n",
    "\n",
    "    global qle_intermediate_medians \n",
    "    global qle_intermediate_means\n",
    "    global qle_intermediate_mins \n",
    "    global qle_intermediate_maxs \n",
    "    global qle_intermediate_std_devs \n",
    "\n",
    "    #qlosses=[]\n",
    "    if iqle_qle == 'qle':\n",
    "        qlosses = qle_qlosses\n",
    "        final_qlosses = qle_final_qloss\n",
    "        qle_type = 'QLE'\n",
    "        differences = qle_differences\n",
    "    elif iqle_qle == 'iqle':\n",
    "        qlosses = iqle_qlosses\n",
    "        final_qlosses = iqle_final_qloss\n",
    "        qle_type = 'IQLE'\n",
    "        differences = iqle_differences\n",
    "\n",
    "    else:\n",
    "        print(\"Needs to either be QLE or IQLE\")\n",
    "        \n",
    "        \n",
    "    ### Format data to be used in plotting\n",
    "        \n",
    "    exp_values = {}\n",
    "    for i in range(num_exp):\n",
    "        exp_values[i] = []\n",
    "\n",
    "    for i in range(num_tests): \n",
    "        for j in range(len(qlosses[i])):\n",
    "            exp_values[j].append(qlosses[i][j])\n",
    "\n",
    "    medians=[]        \n",
    "    std_dev=[]\n",
    "    means=[]\n",
    "    mins=[]\n",
    "    maxs = []\n",
    "    for k in range(num_exp):\n",
    "        try:\n",
    "            medians.append(np.median(exp_values[k]) )\n",
    "            means.append(np.mean(exp_values[k]) )\n",
    "            mins.append(np.min(exp_values[k]) )\n",
    "            maxs.append(np.max(exp_values[k]) )\n",
    "            std_dev.append(np.std(exp_values[k]) )\n",
    "        except ValueError:\n",
    "            pass\n",
    "            \n",
    "    if iqle_qle == 'qle':\n",
    "        qle_intermediate_medians = medians\n",
    "        qle_intermediate_means= means\n",
    "        qle_intermediate_mins = mins\n",
    "        qle_intermediate_maxs= maxs\n",
    "        qle_intermediate_std_devs= std_dev\n",
    "        \n",
    "        qle_all_medians.append(medians)\n",
    "        qle_all_means.append(means)\n",
    "        qle_all_mins.append(mins)\n",
    "        qle_all_maxs.append(maxs)\n",
    "        qle_all_std_devs.append(std_dev)\n",
    "        qle_descriptions_of_runs.append(description)\n",
    "        \n",
    "        \n",
    "    elif iqle_qle == 'iqle':\n",
    "        iqle_intermediate_medians = medians\n",
    "        iqle_intermediate_means = means\n",
    "        iqle_intermediate_mins = mins\n",
    "        iqle_intermediate_maxs = maxs\n",
    "        iqle_intermediate_std_devs = std_dev\n",
    "        \n",
    "        iqle_all_medians.append(medians)\n",
    "        iqle_all_means.append(means)\n",
    "        iqle_all_mins.append(mins)\n",
    "        iqle_all_maxs.append(maxs)\n",
    "        iqle_all_std_devs.append(std_dev)\n",
    "        iqle_descriptions_of_runs.append(description)\n",
    "    \n",
    "#    old_descriptions_of_runs[len(old_descriptions_of_runs)] = description\n",
    "    \n",
    "    \n",
    "def individual_plots(iqle_qle):            \n",
    "    if iqle_qle == 'qle':\n",
    "        qlosses = qle_qlosses\n",
    "        final_qlosses = qle_final_qloss\n",
    "        qle_type = 'QLE'\n",
    "        differences = qle_differences\n",
    "        medians = qle_intermediate_medians\n",
    "        means = qle_intermediate_means\n",
    "        mins = qle_intermediate_mins\n",
    "        maxs = qle_intermediate_maxs\n",
    "        std_devs = qle_intermediate_std_devs\n",
    "        \n",
    "    elif iqle_qle == 'iqle':\n",
    "        qlosses = iqle_qlosses\n",
    "        final_qlosses = iqle_final_qloss\n",
    "        qle_type = 'IQLE'\n",
    "        differences = iqle_differences\n",
    "        medians = iqle_intermediate_medians\n",
    "        means = iqle_intermediate_means\n",
    "        mins = iqle_intermediate_mins\n",
    "        maxs = iqle_intermediate_maxs\n",
    "        std_devs = iqle_intermediate_std_devs\n",
    "    else:\n",
    "        print(\"Needs to either be QLE or IQLE\")\n",
    "\n",
    "    ##### Plots #####\n",
    "    ### Overall results\n",
    "    \n",
    "    # Errors histogram\n",
    "    # %matplotlib inline\n",
    "    plot_description = 'Errors_histogram'\n",
    "    plt.clf()\n",
    "    plt.hist(differences, normed=False, bins=30)\n",
    "    plt.ylabel('Count of '+ qle_type +' runs');\n",
    "    plt.xlabel('Error');\n",
    "    plt.title('Count of '+ qle_type +' runs by error margin '+title_appendix);\n",
    "    if save_figs: plt.savefig(plot_directory+qle_type+'_'+ plot_description)\n",
    "    \n",
    "    # Quadratic Loss histogram\n",
    "    # %matplotlib inline\n",
    "    plot_description='Final_quadratic_loss'\n",
    "    plt.clf()\n",
    "    plt.hist(final_qlosses, normed=False, bins=30)\n",
    "    plt.ylabel('Count of ' +qle_type+' runs');\n",
    "    plt.xlabel('Error');\n",
    "    plt.title('Count of ' +qle_type+' runs by final Quadratic Loss '+title_appendix);\n",
    "    if save_figs: plt.savefig(plot_directory+qle_type+'_'+ plot_description)\n",
    "\n",
    "    # Quadratic loss development of all tests \n",
    "    # %matplotlib inline\n",
    "    plot_description='All_quadratic_loss'\n",
    "    plt.clf()\n",
    "    for i in range(num_tests):\n",
    "        plt.semilogy( range(1,1+len(qlosses[i])), list(qlosses[i]))\n",
    "    plt.xlabel('Experiment Number');\n",
    "    plt.ylabel('Quadratic Loss');\n",
    "    plt.title(qle_type+' Quadratic Loss per experiment '+title_appendix);\n",
    "    if save_figs: plt.savefig(plot_directory+qle_type+'_'+ plot_description)\n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    ### Averages\n",
    "    \n",
    "    \"\"\"\n",
    "    # Median Quadratic loss with error bar\n",
    "    # Not useful here but kept for use case of errorbar function\n",
    "    # %matplotlib inline\n",
    "    plot_description = 'Median_with_error_bar'\n",
    "    plt.clf()\n",
    "    y = medians\n",
    "    x = range(1,1+num_exp)\n",
    "    err = std_dev\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.errorbar(x, y, yerr=err)\n",
    "    ax.set_yscale('log', nonposy=\"clip\")\n",
    "    ax.set_xscale('linear')\n",
    "    plt.xlabel('Experiment Number');\n",
    "    plt.ylabel('Quadratic Loss');\n",
    "    plt.title(qle_type + ' Median Quadratic Loss '+title_appendix);\n",
    "    plt.savefig(plot_directory+qle_type+'_'+ plot_description)\n",
    "    \"\"\"\n",
    "    # Median with shadowing\n",
    "    # %matplotlib inline\n",
    "    plot_description = 'Median_with_std_dev'\n",
    "    plt.clf()\n",
    "    #plt.axes.Axes.set_yscale('log')\n",
    "    y = medians\n",
    "    x = range(1,1+num_exp)\n",
    "    y_lower = [ (y[i] - std_devs[i]) for i in range(len(y))]\n",
    "    y_upper = [ (y[i] + std_devs[i]) for i in range(len(y))]\n",
    "    \n",
    "    fig,ax = plt.subplots()\n",
    "    ax.set_yscale('log', nonposy=\"clip\")\n",
    "    ax.set_xscale('linear')\n",
    "\n",
    "    plt.plot(x,y)\n",
    "    plt.fill_between(x, y_lower, y_upper, alpha=0.2, linewidth=0)\n",
    "\n",
    "    plt.xlabel('Experiment Number');\n",
    "    plt.ylabel('Quadratic Loss');\n",
    "    plt.title(qle_type + ' Median Quadratic Loss '+title_appendix);\n",
    "    if save_figs: plt.savefig(plot_directory+qle_type+'_'+ plot_description)\n",
    "\n",
    "    # Median with shadowing\n",
    "    # %matplotlib inline\n",
    "    plot_description = 'Median_min_max'\n",
    "    plt.clf()\n",
    "    #plt.axes.Axes.set_yscale('log')\n",
    "    y = medians\n",
    "    x = range(1,1+num_exp)\n",
    "    y_lower = maxs\n",
    "    y_upper = mins\n",
    "    \n",
    "    fig,ax = plt.subplots()\n",
    "    ax.set_yscale('log', nonposy=\"clip\")\n",
    "    ax.set_xscale('linear')\n",
    "\n",
    "    plt.plot(x,y)\n",
    "    plt.fill_between(x, y_lower, y_upper, alpha=0.2, linewidth=0)\n",
    "\n",
    "    plt.xlabel('Experiment Number');\n",
    "    plt.ylabel('Quadratic Loss');\n",
    "    plt.title(qle_type + ' Median Quadratic Loss (Min/Max) '+title_appendix);\n",
    "    if save_figs: plt.savefig(plot_directory+qle_type+'_'+ plot_description)\n",
    "        \n",
    "    \n",
    "    # Mean with shadowing\n",
    "    # %matplotlib inline\n",
    "    plot_description = 'Mean_with_std_dev'\n",
    "    plt.clf()\n",
    "    #plt.axes.Axes.set_yscale('log')\n",
    "    y = means\n",
    "    x = range(1,1+num_exp)\n",
    "    \n",
    "    y_lower = [( y[i] - std_devs[i]) for i in range(len(y))]\n",
    "    y_upper = [ (y[i] + std_devs[i] )for i in range(len(y))]\n",
    "    \n",
    "    fig,ax = plt.subplots()\n",
    "    ax.set_yscale('log', nonposy=\"clip\")\n",
    "    ax.set_xscale('linear')\n",
    "\n",
    "    plt.plot(x,y)\n",
    "    plt.fill_between(x, y_lower, y_upper, alpha=0.2, linewidth=0)\n",
    "\n",
    "    plt.xlabel('Experiment Number');\n",
    "    plt.ylabel('Quadratic Loss');\n",
    "    plt.title(qle_type + ' Mean Quadratic Loss '+title_appendix);\n",
    "    if save_figs: plt.savefig(plot_directory+qle_type+'_'+ plot_description)\n",
    "\n",
    "    # Mean with shadowing for min/max\n",
    "    # %matplotlib inline\n",
    "    plot_description = 'Mean_min_max'\n",
    "    plt.clf()\n",
    "    #plt.axes.Axes.set_yscale('log')\n",
    "    y = means\n",
    "    x = range(1,1+num_exp)\n",
    "    y_lower = mins\n",
    "    y_upper = maxs\n",
    "    \n",
    "    fig,ax = plt.subplots()\n",
    "    ax.set_yscale('log', nonposy=\"clip\")\n",
    "    ax.set_xscale('linear')\n",
    "\n",
    "    plt.plot(x,y)\n",
    "    plt.fill_between(x, y_lower, y_upper, alpha=0.2, linewidth=0)\n",
    "\n",
    "    plt.xlabel('Experiment Number');\n",
    "    plt.ylabel('Quadratic Loss');\n",
    "    plt.title(qle_type + ' Mean Quadratic Loss (Max/Min) '+title_appendix);\n",
    "    if save_figs: plt.savefig(plot_directory+qle_type+'_'+ plot_description)\n",
    "\n",
    "    \n",
    "def draw_summary_plots(iqle_qle):\n",
    "    if iqle_qle == 'qle':\n",
    "        qlosses = qle_qlosses\n",
    "        final_qlosses = qle_final_qloss\n",
    "        qle_type = 'QLE'\n",
    "        differences = qle_differences\n",
    "        all_qlosses = all_qle_final_qlosses\n",
    "        descriptions_of_runs = qle_descriptions_of_runs\n",
    "        all_medians = qle_all_medians\n",
    "        all_means = qle_all_means\n",
    "        all_mins = qle_all_mins\n",
    "        all_maxs = qle_all_maxs\n",
    "        all_std_devs = qle_all_std_devs\n",
    "\n",
    "    elif iqle_qle == 'iqle':\n",
    "        qlosses = iqle_qlosses\n",
    "        final_qlosses = iqle_final_qloss\n",
    "        qle_type = 'IQLE'\n",
    "        differences = iqle_differences\n",
    "        all_qlosses = all_iqle_final_qlosses\n",
    "        descriptions_of_runs = iqle_descriptions_of_runs\n",
    "        all_medians = iqle_all_medians\n",
    "        all_means = iqle_all_means\n",
    "        all_mins = iqle_all_mins\n",
    "        all_maxs = iqle_all_maxs\n",
    "        all_std_devs = iqle_all_std_devs\n",
    "    else:\n",
    "        print(\"Needs to either be QLE or IQLE\")\n",
    "        \n",
    "    # Save summary data\n",
    "    if save_summary_data: \n",
    "        all_qlosses_name = summary_plot_directory+qle_type+'_All_Qlosses.txt'\n",
    "        all_medians_name = summary_plot_directory+qle_type+'_All_Medians.txt' \n",
    "        all_means_name = summary_plot_directory+qle_type+'_All_Means.txt' \n",
    "        all_mins_name = summary_plot_directory+qle_type+'_All_Mins.txt' \n",
    "        all_maxs_name = summary_plot_directory+qle_type+'_All_Maxs.txt' \n",
    "        all_std_dev_name = summary_plot_directory+qle_type+'_All_Std_dev.txt' \n",
    "        np.savetxt(all_qlosses_name, all_qlosses)\n",
    "        np.savetxt(all_medians_name, all_medians)\n",
    "        np.savetxt(all_means_name, all_means)\n",
    "        np.savetxt(all_mins_name, all_mins)\n",
    "        np.savetxt(all_maxs_name, all_maxs)\n",
    "        np.savetxt(all_std_dev_name, all_std_devs)\n",
    "    \n",
    "    # Correlation diagram between Quadratic Loss and distance of true param from center of prior    \n",
    "    distance_from_center = [ item - 0.5 for item in all_true_params_single_list]\n",
    "    # %matplotlib inline\n",
    "    plot_description = 'Correlation_distance_quad_loss_'+variable_parameter\n",
    "    plt.clf()\n",
    "    plt.xlabel('Distance from center of Prior distribution')\n",
    "    plt.ylabel('Final Quadratic Loss')\n",
    "    plt.gca().set_yscale('log')\n",
    "    x = distance_from_center\n",
    "    y = all_qlosses\n",
    "    plt.scatter(x,y)        \n",
    "    plt.title(qle_type + ' Correlation between distance from center and final quadratic loss');\n",
    "    plt.savefig(summary_plot_directory+qle_type+'_'+ plot_description)\n",
    "\n",
    "    \n",
    "    # Median Quadratic loss with variable resampling threshold\n",
    "    # %matplotlib inline\n",
    "    plot_description='Median_Q_Loss_w_variable_'+variable_parameter\n",
    "    plt.clf()\n",
    "    for i in range(len(all_medians)):\n",
    "        plt.semilogy( range(1,1+(num_exp)), list(all_medians[i]), label=descriptions_of_runs[i])\n",
    "\n",
    "#    plt.ylim(min(all_medians),max(all_medians) )  \n",
    "    ax = plt.subplot(111)\n",
    "    ## Shrink current axis's height by 10% on the bottom\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "    ## Put a legend below current axis\n",
    "    lgd=ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "              fancybox=True, shadow=True, ncol=4)\n",
    "\n",
    "    plt.xlabel('Experiment Number');\n",
    "    plt.ylabel('Quadratic Loss');\n",
    "    plt.title(qle_type+' Median Quadratic Loss with variable '+ variable_parameter);\n",
    "    plt.savefig(summary_plot_directory+qle_type+'_'+ plot_description, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "\n",
    "\n",
    "    # Mean Quadratic loss with variable resampling threshold\n",
    "    # %matplotlib inline\n",
    "    plot_description='Mean_Q_Loss_w_variable_'+variable_parameter\n",
    "    plt.clf()\n",
    "    for i in range(len(all_medians)):\n",
    "        plt.semilogy( range(1,1+(num_exp)), list(all_means[i]), label=descriptions_of_runs[i])\n",
    "\n",
    " #   plt.ylim(min(all_means),max(all_means) )  \n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    # Shrink current axis's height by 10% on the bottom\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1,\n",
    "                     box.width, box.height * 0.9])\n",
    "\n",
    "    # Put a legend below current axis\n",
    "    lgd=ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15),\n",
    "              fancybox=True, shadow=True, ncol=4)\n",
    "\n",
    "    plt.xlabel('Experiment Number');\n",
    "    plt.ylabel('Quadratic Loss');\n",
    "    plt.title(qle_type+' Mean Quadratic Loss with variable '+ variable_parameter);\n",
    "    plt.savefig(summary_plot_directory+qle_type+'_'+ plot_description, bbox_extra_artists=(lgd,), bbox_inches='tight')\n",
    "\n",
    "\n",
    "\n",
    "##########################################\n",
    "\n",
    "####### run loops \n",
    "\n",
    "#########################################\n",
    "\n",
    "\n",
    "# This cell runs tests on IQLE and QLE and plots the resulting errors and quadratic losses\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time as time \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from __future__ import print_function # so print doesn't show brackets\n",
    "import numpy as np\n",
    "import itertools as itr\n",
    "\n",
    "import imp\n",
    "import os as os\n",
    "import sys as sys \n",
    "import pandas as pd\n",
    "import warnings\n",
    "import time as time\n",
    "import random\n",
    "\n",
    "sys.path.append(os.path.join(\"..\", \"..\",\"Libraries\",\"QML_lib\"))\n",
    "import Evo as evo\n",
    "import DataBase \n",
    "import QMD\n",
    "import QML\n",
    "import ModelGeneration\n",
    "import BayesF\n",
    "import matplotlib\n",
    "paulis = ['x', 'y', 'z'] # will be chosen at random. or uncomment below and comment within loop to hard-set\n",
    "\n",
    "imp.reload(evo)\n",
    "imp.reload(DataBase)\n",
    "\n",
    "num_tests = 2\n",
    "num_exp = 5\n",
    "num_part = 10\n",
    "\n",
    "global_true_op = 'xTxTTxTTTyTTTTxTTTTTyTTTTTTxTTTTTTTxTTTTTTTTy'\n",
    "#global_true_op = 'xTxTTxTTTyTTTTx'\n",
    "#global_true_op = 'xTx'\n",
    "\n",
    "\n",
    "all_true_ops = []\n",
    "all_true_params = []\n",
    "all_true_params_single_list = []\n",
    "all_qle_final_qlosses = []\n",
    "all_iqle_final_qlosses = []\n",
    "\n",
    "qle_all_medians = []\n",
    "qle_all_means = []\n",
    "qle_all_maxs = []\n",
    "qle_all_mins = []\n",
    "qle_all_std_devs = []\n",
    "\n",
    "iqle_all_medians = []\n",
    "iqle_all_means = []\n",
    "iqle_all_maxs = []\n",
    "iqle_all_mins = []\n",
    "iqle_all_std_devs = []\n",
    "\n",
    "\n",
    "\n",
    "iqle_descriptions_of_runs = []\n",
    "qle_descriptions_of_runs = []\n",
    "old_descriptions_of_runs = {}\n",
    "\n",
    "a = time.time()\n",
    "\n",
    "\n",
    "for resample_thresh in resample_threshold_options:\n",
    "    for resample_a in a_options:\n",
    "        for pgh_factor in pgh_options:\n",
    "            \"\"\"\n",
    "            iqle_intermediate_medians=[]\n",
    "            iqle_intermediate_means=[]\n",
    "            iqle_intermediate_mins=[]\n",
    "            iqle_intermediate_maxs=[]\n",
    "            iqle_intermediate_std_devs=[]\n",
    "\n",
    "            qle_intermediate_medians = []\n",
    "            qle_intermediate_means=[]\n",
    "            qle_intermediate_mins=[]\n",
    "            qle_intermediate_maxs=[]\n",
    "            qle_intermediate_std_devs=[]\n",
    "            \"\"\"\n",
    "\n",
    "            qle_list = []\n",
    "            iqle_list = []\n",
    "            true_param_list = []\n",
    "            true_op_list =[]\n",
    "            qle_differences = []\n",
    "            iqle_differences = []\n",
    "            qle_qlosses = []\n",
    "            qle_final_qloss =[]\n",
    "            iqle_qlosses =[]\n",
    "            iqle_final_qloss =[]\n",
    "\n",
    "            global iqle_intermediate_medians \n",
    "            global iqle_intermediate_means\n",
    "            global iqle_intermediate_mins \n",
    "            global iqle_intermediate_maxs \n",
    "            global iqle_intermediate_std_devs \n",
    "\n",
    "            global qle_intermediate_medians \n",
    "            global qle_intermediate_means\n",
    "            global qle_intermediate_mins \n",
    "            global qle_intermediate_maxs \n",
    "            global qle_intermediate_std_devs \n",
    "\n",
    "            for i in range(num_tests):\n",
    "                true_params = [np.random.rand()]\n",
    "                true_param_list.append(true_params[0])\n",
    "                true_op=np.random.choice(paulis) # to choose a random True model each time \n",
    "\n",
    "                true_op = global_true_op\n",
    "                #true_op = 'xTxTTxTTTxTTTTxTTTTTx'\n",
    "                # true_op = 'xTxTTxTTTxTTTTxTTTTTxTTTTTTxTTTTTTTxTTTTTTTTxTTTTTTTTTx'\n",
    "                true_op_list.append(true_op)\n",
    "                # (Note: not learning between models yet; just learning paramters of true model)\n",
    "\n",
    "                qle_values = [] # qle True does QLE; False does IQLE\n",
    "                if do_qle is True:\n",
    "                    qle_values.append(True)\n",
    "                if do_iqle is True:\n",
    "                    qle_values.append(False)\n",
    "\n",
    "                for qle in qle_values:\n",
    "                    qmd = NewQMDClass(\n",
    "                        initial_op_list=[true_op], \n",
    "                        true_operator=true_op, \n",
    "                        true_param_list=true_params, \n",
    "                        num_particles=num_part,\n",
    "                        qle=qle,\n",
    "                        resample_threshold = resample_thresh,\n",
    "                        resampler_a = resample_a,\n",
    "                        pgh_prefactor = pgh_factor\n",
    "                    )\n",
    "                    qmd.runAllActiveModelsIQLE(num_exp=num_exp)\n",
    "\n",
    "                    mod = qmd.getModelInstance(true_op)\n",
    "                    if qle is True:\n",
    "                        qle_list.append(mod.FinalParams[0][0])\n",
    "                        qle_qlosses.append(mod.QLosses)\n",
    "                        qle_final_qloss.append(mod.QLosses[-1])\n",
    "                    else: \n",
    "                        iqle_list.append(mod.FinalParams[0][0])\n",
    "                        iqle_qlosses.append(mod.QLosses)\n",
    "                        iqle_final_qloss.append(mod.QLosses[-1])\n",
    "\n",
    "                    qmd.killModel(true_op)\n",
    "                    del qmd\n",
    "\n",
    "            all_true_params.append(true_param_list)\n",
    "            all_true_params_single_list.extend(true_param_list)\n",
    "            all_true_ops.append(true_op_list)\n",
    "            all_qle_final_qlosses.extend(qle_final_qloss)\n",
    "            all_iqle_final_qlosses.extend(iqle_final_qloss)\n",
    "\n",
    "\n",
    "\n",
    "            for i in range(num_tests):\n",
    "                if do_iqle:\n",
    "                    iqle_diff =np.abs(true_param_list[i]-iqle_list[i])\n",
    "                    iqle_differences.append(iqle_diff)\n",
    "                if do_qle:\n",
    "                    qle_diff =np.abs(true_param_list[i]-qle_list[i])\n",
    "                    qle_differences.append(qle_diff)\n",
    "\n",
    "\n",
    "\n",
    "            # Plotting\n",
    "            title_appendix = str( '(single parameter, ' +str(num_tests)+' runs)')\n",
    "\n",
    "            plot_title_appendix = str( str(num_exp)+'_exp_'+str(num_part)+'_particles_'+str(num_tests)+'_runs')\n",
    "            #plot_directory = 'test_plots/'+plot_time\n",
    "            param_details = str('thresh_'+str(resample_thresh)+'_a_'+str(resample_a)+'_pgh_'+str(pgh_factor))\n",
    "\n",
    "            #plot_directory = 'test_plots/'+plot_time+'/'+plot_title_appendix+'/'+\n",
    "            plot_directory = 'test_plots/'+plot_time+'/'+plot_title_appendix+'/'+param_details+'/'\n",
    "\n",
    "            if do_intermediate_plots:\n",
    "                if not os.path.exists(plot_directory):\n",
    "                    os.makedirs(plot_directory)\n",
    "\n",
    "            description = str('('+ str(resample_thresh)+ ', '+ str(resample_a) + ', '+ str(pgh_factor)+')')\n",
    "            #print(\"description : \", description)\n",
    "            if do_iqle:\n",
    "                store_data_for_plotting('iqle')\n",
    "                if intermediate_plots: individual_plots('iqle')\n",
    "\n",
    "            if do_qle:  \n",
    "                print(\"storing data for QLE\")\n",
    "                store_data_for_plotting('qle')\n",
    "                if intermediate_plots: individual_plots('qle')\n",
    "\n",
    "            names_to_save = ['true_param_list', 'true_op_list']\n",
    "            lists_to_save = [true_param_list, true_op_list]\n",
    "\n",
    "            if do_qle:\n",
    "                names_to_save.extend(['qle_list', 'qle_qlosses', 'qle_final_qloss'])\n",
    "                lists_to_save.extend([qle_list, qle_qlosses, qle_final_qloss])\n",
    "\n",
    "            if do_iqle:\n",
    "                names_to_save.extend(['iqle_list', 'iqle_qlosses', 'iqle_final_qloss'])\n",
    "                lists_to_save.extend([iqle_list, iqle_qlosses, iqle_final_qloss])\n",
    "\n",
    "            running_data = dict(zip(names_to_save, lists_to_save))\n",
    "\n",
    "\n",
    "            for item in running_data.keys():\n",
    "                filename = plot_directory+str(item)+'.txt'\n",
    "                data_to_save = running_data[item]\n",
    "                if type(data_to_save)==list:\n",
    "                    if save_intermediate_data: np.savetxt(filename, data_to_save, fmt=\"%s\")    \n",
    "                else: \n",
    "                    if save_intermediate_data: np.savetxt(filename, data_to_save)  \n",
    "\n",
    "summary_plot_directory = 'test_plots/'+plot_time+'/'+plot_title_appendix+'/Summary_Plots/'\n",
    "if do_summary_plots:\n",
    "    if not os.path.exists(summary_plot_directory):\n",
    "        os.makedirs(summary_plot_directory)\n",
    "                \n",
    "if do_iqle:\n",
    "    if do_summary_plots: \n",
    "        draw_summary_plots('iqle')\n",
    "    \n",
    "    \n",
    "if do_qle:\n",
    "    if do_summary_plots:\n",
    "        draw_summary_plots('qle')\n",
    "        \n",
    "    \n",
    "b = time.time()\n",
    "\n",
    "print(\"\\n\\n\\n\\n\\n\\nTIME TAKEN FOR \", num_tests, \"TESTS : \", b-a)\n",
    "\n",
    "\n",
    "import sys\n",
    "import inspect\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects in bytes\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        for cls in obj.__class__.__mro__:\n",
    "            if '__dict__' in cls.__dict__:\n",
    "                d = cls.__dict__['__dict__']\n",
    "                if inspect.isgetsetdescriptor(d) or inspect.ismemberdescriptor(d):\n",
    "                    size += get_size(obj.__dict__, seen)\n",
    "                break\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum((get_size(v, seen) for v in obj.values()))\n",
    "        size += sum((get_size(k, seen) for k in obj.keys()))\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum((get_size(i, seen) for i in obj))\n",
    "    return size\n",
    "\n",
    "def print_memory_usage(my_object, big_size):\n",
    "    print(\"Total memory used by object : \", get_size(my_object)/10**6, \"MB\")\n",
    "    my_memory = {}\n",
    "    for item in dir(my_object):\n",
    "        if item in dir(my_object):\n",
    "            my_memory[item] = get_size(my_object.__getattribute__(item))/10**6\n",
    "#        print(repr(item), get_size(my_object.__getattribute__(item))/10**6)\n",
    "    \n",
    "    for key in my_memory.keys():\n",
    "        if my_memory[key] > big_size:\n",
    "            print(key, \" : \", my_memory[key])                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psutil import virtual_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "virtual_memory().percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op=qmd.getOperatorInstance('xTxTTxTTTyTTTTxTTTTTyTTTTTTxTTTTTTTxTTTTTTTTy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects in bytes\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        for cls in obj.__class__.__mro__:\n",
    "            if '__dict__' in cls.__dict__:\n",
    "                d = cls.__dict__['__dict__']\n",
    "                if inspect.isgetsetdescriptor(d) or inspect.ismemberdescriptor(d):\n",
    "                    size += get_size(obj.__dict__, seen)\n",
    "                break\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum((get_size(v, seen) for v in obj.values()))\n",
    "        size += sum((get_size(k, seen) for k in obj.keys()))\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum((get_size(i, seen) for i in obj))\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_size(qmd.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_size(_i11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allobjs = dir()\n",
    "\n",
    "for obj in allobjs:\n",
    "    try:\n",
    "        \n",
    "        mem_used = get_size(obj)/10**3\n",
    "        if mem_used > 0:\n",
    "            print(\"obj is \", obj)\n",
    "            print(mem_used, \"KB\")\n",
    "    except:\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qinfer as qinfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_particles = int(5e6)\n",
    "perf = qinfer.perf_test(\n",
    "qinfer.SimplePrecessionModel(), n_particles,\n",
    "qinfer.UniformDistribution([0, 1]), 100,\n",
    " qinfer.ExpSparseHeuristic\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"For \", num_part,\" particles  and \", num_exp, \" experiments: \\n\")\n",
    "print(\" total size \", get_size(mod)/10**6,  \"MB\")\n",
    "print(\" updater \", get_size(mod.Updater)/10**6,  \"MB\")\n",
    "print(\"updater is \", 100*get_size(mod.Updater)/get_size(mod), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen=mod.GenSimModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_memory_usage(mod, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probes = gen._probelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(probes)/10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod.Updater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hamiltonian_exponentiation as h\n",
    "import sys, os\n",
    "sys.path.append(os.path.join(\"..\", \"..\",\"Libraries\",\"QML_lib\"))\n",
    "import Evo as evo\n",
    "import DataBase \n",
    "\n",
    "op = 'xTxTTxTTTyTTTTxTTTTTyTTTTTTxTTTTTTTxTTTTTTTTy'\n",
    "ham=DataBase.operator(op).matrix\n",
    "\n",
    "import inspect\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects in bytes\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if hasattr(obj, '__dict__'):\n",
    "        for cls in obj.__class__.__mro__:\n",
    "            if '__dict__' in cls.__dict__:\n",
    "                d = cls.__dict__['__dict__']\n",
    "                if inspect.isgetsetdescriptor(d) or inspect.ismemberdescriptor(d):\n",
    "                    size += get_size(obj.__dict__, seen)\n",
    "                break\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum((get_size(v, seen) for v in obj.values()))\n",
    "        size += sum((get_size(k, seen) for k in obj.keys()))\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum((get_size(i, seen) for i in obj))\n",
    "    return size\n",
    "\n",
    "def print_memory_usage(my_object, big_size):\n",
    "    print(\"Total memory used by object : \", get_size(my_object)/10**6, \"MB\")\n",
    "    my_memory = {}\n",
    "    for item in dir(my_object):\n",
    "        if item in dir(my_object):\n",
    "            my_memory[item] = get_size(my_object.__getattribute__(item))/10**6\n",
    "#        print(repr(item), get_size(my_object.__getattribute__(item))/10**6)\n",
    "    \n",
    "    for key in my_memory.keys():\n",
    "        if my_memory[key] > big_size:\n",
    "            print(key, \" : \", my_memory[key])                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham = h.exp_ham(ham, t=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 1\n",
    "from scipy import linalg\n",
    "\n",
    "for num_qubits in range(1,13):\n",
    "    print(\"num qubits = \", num_qubits)\n",
    "    try:\n",
    "        ham = h.random_hamiltonian(num_qubits)\n",
    "        expd_ham = h.exp_ham(ham, 1)\n",
    "        print(\"CUSTOM:\")\n",
    "        print_memory_usage(expd_ham, 0.01)\n",
    "        lin_exp = linalg.expm(-1j*ham)\n",
    "        print(\"LINALG:\")\n",
    "        print_memory_usage(lin_exp, 0.01)\n",
    "        \n",
    "    except:\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_qubits = 1\n",
    "from scipy import linalg\n",
    "\n",
    "for num_qubits in range(1,13):\n",
    "    print(\"num qubits = \", num_qubits)\n",
    "    try:\n",
    "        ham = h.random_hamiltonian(num_qubits)\n",
    "        lin_exp = linalg.expm(-1j*ham)\n",
    "        print(\"LINALG:\")\n",
    "        print_memory_usage(lin_exp, 0.01)\n",
    "        \n",
    "    except:\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load ../../Evo.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vo.getH()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
